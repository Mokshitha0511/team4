{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3qevPvhn_-uL",
        "outputId": "0bf082ac-e47d-4c11-f819-a18d9a5fc6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'team4'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 121 (delta 41), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (121/121), 44.37 KiB | 721.00 KiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "/content/team4/diversify\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.15.3)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.1->-r requirements.txt (line 1)) (3.0.2)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d9f357e2347f458383f61372f810e1e0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# First clone the repository\n",
        "!git clone https://github.com/Mokshitha0511/team4.git\n",
        "%cd team4/diversify\n",
        "\n",
        "# Then install from local requirements file\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
        "!unzip diversity_emg.zip && mv emg data/\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p ./data/train_output/act/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz-ZPcgMABJQ",
        "outputId": "523ea532-19cd-4793-d97f-474072a75dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-29 22:13:17--  https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
            "Resolving wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)... 20.60.131.4\n",
            "Connecting to wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)|20.60.131.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20237244 (19M) [application/zip]\n",
            "Saving to: ‘diversity_emg.zip’\n",
            "\n",
            "diversity_emg.zip   100%[===================>]  19.30M  3.66MB/s    in 6.3s    \n",
            "\n",
            "2025-06-29 22:13:24 (3.06 MB/s) - ‘diversity_emg.zip’ saved [20237244/20237244]\n",
            "\n",
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip diversity_emg.zip\n",
        "!mkdir -p ./data/emg\n",
        "!mv emg/* ./data/emg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW_qszJSAEQt",
        "outputId": "88ebe876-dd22-4d47-9139-8c19b27b348d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 0 --dataset emg --algorithm diversify --latent_domain_num 10 --alpha1 1.0 --alpha 1.0 --lam 0.0 --local_epoch 3 --max_epoch 10 --lr 0.01 --curriculum --output ./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzxNIS0xAHLo",
        "outputId": "15a9ae76-5b7a-473d-be78-9c7701961708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:1.0\n",
            "alpha1:1.0\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:10\n",
            "local_epoch:3\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[0]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01\n",
            "weight_decay:0.0005\n",
            "curriculum:True\n",
            "CL_PHASE_EPOCHS:5\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "========ROUND 0========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 1.7833\n",
            "2. Domain 0.0: Avg Val Loss = 1.7902\n",
            "3. Domain 1.0: Avg Val Loss = 1.7957\n",
            "Curriculum learning: Stage 0\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6397816539    \n",
            "1                0.4608092010    \n",
            "2                0.5361940861    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6499248147     0.5602661371     0.0896586552    \n",
            "1                1.1091725826     1.0987671614     0.0104053989    \n",
            "2                0.8545578122     0.8520415425     0.0025162601    \n",
            "Counter({9: 845, 6: 659, 8: 322, 0: 277, 2: 243, 7: 142, 4: 133, 5: 92, 3: 64, 1: 28})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4635429382     0.0022540323     0.4657969773     0.8168436293     0.8222222222     0.7130281690     1.2321264744    \n",
            "1                0.4059674442     0.0013004721     0.4072679281     0.8277027027     0.8396135266     0.6930751174     2.3749153614    \n",
            "2                0.3488042951     0.0020211765     0.3508254588     0.8535231660     0.8695652174     0.6977699531     3.5165202618    \n",
            "\n",
            "========ROUND 1========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 0.3387\n",
            "2. Domain 0.0: Avg Val Loss = 0.4325\n",
            "3. Domain 1.0: Avg Val Loss = 0.8035\n",
            "Curriculum learning: Stage 1\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3450095356    \n",
            "1                0.2391744554    \n",
            "2                0.3040024042    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6494862437     0.6485192180     0.0009670232    \n",
            "1                0.6874766350     0.6869355440     0.0005410800    \n",
            "2                0.6144698262     0.6138680577     0.0006017427    \n",
            "Counter({9: 2805})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2876727283     0.0039254827     0.2915982008     0.8293918919     0.8357487923     0.7136150235     1.2234942913    \n",
            "1                0.2229662538     0.0010190830     0.2239853442     0.8658301158     0.8743961353     0.7130281690     2.3329987526    \n",
            "2                0.2787628770     0.0001094398     0.2788723111     0.8161196911     0.8367149758     0.6519953052     3.4672505856    \n",
            "\n",
            "========ROUND 2========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 0.4943\n",
            "2. Domain 2.0: Avg Val Loss = 0.5158\n",
            "3. Domain 1.0: Avg Val Loss = 1.1644\n",
            "Curriculum learning: Stage 2\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2988556325    \n",
            "1                0.2806291580    \n",
            "2                0.3715160489    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.8911554813     0.8906365633     0.0005189403    \n",
            "1                0.7872809768     0.7867751718     0.0005058191    \n",
            "2                0.9002894759     0.8998153210     0.0004741726    \n",
            "Counter({0: 1588, 8: 794, 5: 442, 6: 390, 7: 272, 1: 185, 2: 144, 4: 128, 3: 125, 9: 74})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2990293503     0.0004568651     0.2994862199     0.8658301158     0.8763285024     0.6643192488     1.2997956276    \n",
            "1                0.2632762492     0.0003877211     0.2636639774     0.9085424710     0.9120772947     0.7147887324     2.9233229160    \n",
            "2                0.2281562984     0.0004691856     0.2286254913     0.9160231660     0.9159420290     0.7053990610     4.5633161068    \n",
            "\n",
            "========ROUND 3========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 0.2822\n",
            "2. Domain 2.0: Avg Val Loss = 0.3042\n",
            "3. Domain 1.0: Avg Val Loss = 0.3681\n",
            "Curriculum learning: Stage 3\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2874147594    \n",
            "1                0.2271977216    \n",
            "2                0.3941709399    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.4046925306     1.4041589499     0.0005335566    \n",
            "1                0.6742081046     0.6737468243     0.0004613073    \n",
            "2                0.8652945757     0.8648498058     0.0004447807    \n",
            "Counter({7: 4142})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1866843700     0.0004695745     0.1871539503     0.9186776062     0.9323671498     0.7124413146     1.3316204548    \n",
            "1                0.2118049115     0.0005803810     0.2123852968     0.8885135135     0.8946859903     0.7071596244     2.6442422867    \n",
            "2                0.2037471831     0.0005300925     0.2042772770     0.9032335907     0.9014492754     0.7077464789     3.9339580536    \n",
            "\n",
            "========ROUND 4========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 1.0: Avg Val Loss = 0.4094\n",
            "2. Domain 2.0: Avg Val Loss = 0.4182\n",
            "3. Domain 0.0: Avg Val Loss = 0.4191\n",
            "Curriculum learning: Stage 4\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2635075748    \n",
            "1                0.3179317117    \n",
            "2                0.3204551935    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7137025595     0.7131885290     0.0005140119    \n",
            "1                0.6776187420     0.6773670316     0.0002516984    \n",
            "2                0.6756334901     0.6752200127     0.0004134933    \n",
            "Counter({0: 1447, 3: 962, 1: 578, 2: 371, 7: 345, 4: 159, 8: 110, 6: 59, 9: 57, 5: 54})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3400292695     0.0005981300     0.3406274021     0.9222972973     0.9285024155     0.7106807512     1.3029425144    \n",
            "1                0.2761542499     0.0004238043     0.2765780687     0.9324324324     0.9420289855     0.7042253521     2.6230826378    \n",
            "2                0.1421187967     0.0004979576     0.1426167488     0.9346042471     0.9333333333     0.7200704225     3.9405303001    \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2305391580    \n",
            "1                0.1725038141    \n",
            "2                0.2883594036    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6952733994     0.6946851611     0.0005882174    \n",
            "1                0.5401893854     0.5397009254     0.0004884518    \n",
            "2                0.7852810621     0.7848486304     0.0004324535    \n",
            "Counter({0: 1210, 9: 837, 5: 652, 4: 290, 7: 290, 1: 250, 6: 243, 3: 238, 2: 77, 8: 55})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1453316063     0.0002318351     0.1455634385     0.9346042471     0.9439613527     0.6784037559     1.8451559544    \n",
            "1                0.1998447627     0.0003983434     0.2002431005     0.9382239382     0.9323671498     0.7065727700     3.2399659157    \n",
            "2                0.1774763018     0.0005334402     0.1780097485     0.9428088803     0.9449275362     0.6883802817     4.5392887592    \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3978044987    \n",
            "1                0.1988178343    \n",
            "2                0.1767933816    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9635816813     0.9629982710     0.0005834036    \n",
            "1                0.9791746736     0.9788329601     0.0003416946    \n",
            "2                0.6891735196     0.6886752248     0.0004983140    \n",
            "Counter({0: 1382, 7: 704, 1: 536, 9: 514, 6: 431, 4: 226, 3: 159, 8: 76, 2: 69, 5: 45})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1578068137     0.0007651233     0.1585719436     0.9186776062     0.9120772947     0.6854460094     1.3145887852    \n",
            "1                0.1738334447     0.0005784736     0.1744119227     0.9464285714     0.9507246377     0.6924882629     2.6026873589    \n",
            "2                0.0751725435     0.0003409998     0.0755135417     0.9527027027     0.9536231884     0.6877934272     4.1175518036    \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2770147026    \n",
            "1                0.1596860439    \n",
            "2                0.0868724361    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.4703991711     0.4699258506     0.0004733262    \n",
            "1                0.5586337447     0.5581308007     0.0005029336    \n",
            "2                0.5504819155     0.5500252247     0.0004566914    \n",
            "Counter({0: 1267, 9: 1015, 1: 556, 3: 333, 4: 261, 8: 236, 5: 192, 2: 136, 7: 86, 6: 60})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1579803228     0.0006578190     0.1586381346     0.9423262548     0.9478260870     0.6901408451     1.3172254562    \n",
            "1                0.0677842498     0.0005280785     0.0683123320     0.9510135135     0.9516908213     0.6737089202     2.6288943291    \n",
            "2                0.0918646008     0.0006766355     0.0925412327     0.9541505792     0.9439613527     0.6707746479     3.9132182598    \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1243194118    \n",
            "1                0.1752851307    \n",
            "2                0.1485731304    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6390332580     0.6384736896     0.0005595507    \n",
            "1                1.2297120094     1.2290879488     0.0006240810    \n",
            "2                0.8718828559     0.8714524508     0.0004304261    \n",
            "Counter({9: 4142})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0822281763     0.0003261034     0.0825542808     0.9358108108     0.9468599034     0.6490610329     1.4739055634    \n",
            "1                0.1205483824     0.0007009659     0.1212493479     0.9555984556     0.9574879227     0.6965962441     2.7814509869    \n",
            "2                0.2043264061     0.0004540414     0.2047804445     0.9194015444     0.9140096618     0.6373239437     4.1174259186    \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2229690403    \n",
            "1                0.2264114767    \n",
            "2                0.0955332369    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7491727471     0.7486596704     0.0005130906    \n",
            "1                0.9940502644     0.9936286211     0.0004216155    \n",
            "2                0.6685369015     0.6680821180     0.0004547647    \n",
            "Counter({0: 1287, 9: 870, 5: 414, 4: 336, 8: 324, 6: 296, 3: 164, 1: 160, 7: 149, 2: 142})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1719762981     0.0002992898     0.1722755879     0.9498069498     0.9458937198     0.6813380282     1.2934224606    \n",
            "1                0.0522105098     0.0003527972     0.0525633059     0.9671814672     0.9623188406     0.6819248826     2.8105223179    \n",
            "2                0.0473113544     0.0005190494     0.0478304029     0.9695945946     0.9613526570     0.6989436620     4.7130124569    \n",
            "Target acc: 0.6819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 1 --dataset emg --algorithm diversify --latent_domain_num 2 --alpha1 0.1 --alpha 10.0 --lam 0.0 --local_epoch 10 --max_epoch 10 --lr 0.01 --curriculum --output ./data/train_output/act/cross_people-emg-Diversify-1-2-0.1-10-0-10-15-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPj2yB4tTMQU",
        "outputId": "ed116498-2a7f-4637-93ea-ce864103370a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:10.0\n",
            "alpha1:0.1\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:2\n",
            "local_epoch:10\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[1]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-1-2-0.1-10-0-10-15-0.01\n",
            "weight_decay:0.0005\n",
            "curriculum:True\n",
            "CL_PHASE_EPOCHS:5\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "========ROUND 0========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 1.7930\n",
            "2. Domain 1.0: Avg Val Loss = 1.7940\n",
            "3. Domain 0.0: Avg Val Loss = 1.7952\n",
            "Curriculum learning: Stage 0\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                3.1773827076    \n",
            "1                0.7033534646    \n",
            "2                0.2410998791    \n",
            "3                5.9729061127    \n",
            "4                1.5745887756    \n",
            "5                4.0844912529    \n",
            "6                0.1411596388    \n",
            "7                2.3434810638    \n",
            "8                0.4735918939    \n",
            "9                3.6050081253    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.2137398720     1.2064610720     0.0072787725    \n",
            "1                2.6394400597     2.6386711597     0.0007689532    \n",
            "2                0.7198926806     0.7195428014     0.0003498972    \n",
            "3                1.3362340927     1.3358064890     0.0004275706    \n",
            "4                2.2558820248     2.2555778027     0.0003042936    \n",
            "5                1.0421433449     1.0417488813     0.0003944543    \n",
            "6                1.4308718443     1.4304556847     0.0004162145    \n",
            "7                2.5697362423     2.5692584515     0.0004776745    \n",
            "8                1.0478823185     1.0473557711     0.0005265298    \n",
            "9                0.6603842378     0.6599905491     0.0003937082    \n",
            "Counter({0: 1870, 1: 821})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                5.6845321655     0.0004702036     5.6850023270     0.7216469428     0.7226061204     0.7205071665     1.4580790997    \n",
            "1                0.9670158029     0.0000592442     0.9670750499     0.8178007890     0.8351431392     0.7932745314     2.8645429611    \n",
            "2                0.1571765542     0.0010902705     0.1582668275     0.8089250493     0.8430404738     0.8070562293     4.2341890335    \n",
            "3                2.1183028221     0.0003527972     2.1186556816     0.6831854043     0.7245804541     0.7205071665     6.2576684952    \n",
            "4                0.9192234874     0.0004253675     0.9196488261     0.7993096647     0.8035538006     0.7739801544     7.8261163235    \n",
            "5                2.3332848549     0.0003054868     2.3335902691     0.6092209073     0.6525172754     0.6251378170     9.1926934719    \n",
            "6                3.6154186726     0.0003803642     3.6157989502     0.7455621302     0.7581441264     0.7116868798     10.5854849815   \n",
            "7                0.4942385256     0.0003868388     0.4946253598     0.7847633136     0.7818361303     0.7750826902     11.9582853317   \n",
            "8                1.6046928167     0.0003766304     1.6050693989     0.7847633136     0.8193484699     0.7828004410     13.3202335835   \n",
            "9                1.5308399200     0.0002461766     1.5310860872     0.6826923077     0.7137216190     0.6560088203     14.6869783401   \n",
            "\n",
            "========ROUND 1========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 0.5791\n",
            "2. Domain 1.0: Avg Val Loss = 0.7842\n",
            "3. Domain 0.0: Avg Val Loss = 1.3461\n",
            "Curriculum learning: Stage 1\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                2.5670664310    \n",
            "1                0.8611133695    \n",
            "2                0.2206991315    \n",
            "3                3.7214596272    \n",
            "4                0.1518800259    \n",
            "5                2.8504149914    \n",
            "6                1.1573795080    \n",
            "7                0.2486474961    \n",
            "8                2.1942310333    \n",
            "9                2.0414307117    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.5249702930     1.5246824026     0.0002879279    \n",
            "1                1.8238922358     1.8235059977     0.0003862799    \n",
            "2                3.1376478672     3.1372950077     0.0003529155    \n",
            "3                2.1716625690     2.1713202000     0.0003424685    \n",
            "4                1.2133085728     1.2128421068     0.0004664747    \n",
            "5                2.1209030151     2.1205573082     0.0003457601    \n",
            "6                1.9631474018     1.9627876282     0.0003597460    \n",
            "7                0.7228035927     0.7224373817     0.0003662203    \n",
            "8                1.1576170921     1.1573023796     0.0003147333    \n",
            "9                1.8348625898     1.8344907761     0.0003717805    \n",
            "Counter({1: 1681, 0: 1010})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3633887768     0.0004457434     0.3638345301     0.7749013807     0.7966436328     0.7723263506     1.4388389587    \n",
            "1                1.8540073633     0.0002992103     1.8543065786     0.7864891519     0.8144126357     0.7679162073     2.8934183121    \n",
            "2                0.6094789505     0.0003997480     0.6098787189     0.8237179487     0.8479763080     0.8020948181     4.9062044621    \n",
            "3                4.0442714691     0.0003744854     4.0446457863     0.8429487179     0.8756169793     0.8263506064     6.2923951149    \n",
            "4                1.5277799368     0.0003773454     1.5281572342     0.8296351085     0.8400789733     0.7844542448     7.6714179516    \n",
            "5                2.2136192322     0.0003587556     2.2139780521     0.8417159763     0.8667324778     0.7982359427     9.0457694530    \n",
            "6                0.2976081669     0.0002629411     0.2978711128     0.7983234714     0.8223099704     0.7921719956     10.4583439827   \n",
            "7                3.4972648621     0.0003624498     3.4976272583     0.7805719921     0.7976307996     0.7590959206     11.8371274471   \n",
            "8                3.5459182262     0.0003442172     3.5462625027     0.8399901381     0.8647581441     0.8042998897     13.2169017792   \n",
            "9                0.0245133583     0.0003282485     0.0248416066     0.8375246548     0.8479763080     0.8009922822     14.6303219795   \n",
            "\n",
            "========ROUND 2========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 0.4045\n",
            "2. Domain 1.0: Avg Val Loss = 0.6168\n",
            "3. Domain 0.0: Avg Val Loss = 1.5880\n",
            "Curriculum learning: Stage 2\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3548320234    \n",
            "1                0.4672125578    \n",
            "2                0.3337192833    \n",
            "3                0.6072029471    \n",
            "4                0.4156880677    \n",
            "5                0.3168813288    \n",
            "6                0.3262146413    \n",
            "7                0.5224179626    \n",
            "8                0.1236209944    \n",
            "9                0.1380193084    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.5396162271     1.5392856598     0.0003305229    \n",
            "1                1.2469948530     1.2467014790     0.0002934331    \n",
            "2                0.8052685261     0.8048892617     0.0003792566    \n",
            "3                1.0718635321     1.0715090036     0.0003545191    \n",
            "4                0.9849421382     0.9846204519     0.0003216614    \n",
            "5                1.3864547014     1.3861161470     0.0003385457    \n",
            "6                0.9139937162     0.9136019349     0.0003917638    \n",
            "7                1.7208942175     1.7205013037     0.0003929494    \n",
            "8                1.3128199577     1.3124651909     0.0003547411    \n",
            "9                1.4099063873     1.4094409943     0.0004654295    \n",
            "Counter({1: 2344, 0: 1710})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4413809478     0.0003915258     0.4417724609     0.9127218935     0.9230009872     0.8158765160     1.5758061409    \n",
            "1                0.2501758635     0.0003943641     0.2505702376     0.9072978304     0.9081934847     0.7971334068     3.1391668320    \n",
            "2                0.6364996433     0.0003305128     0.6368301511     0.9080374753     0.9160908193     0.8213891951     4.7266435623    \n",
            "3                0.5645485520     0.0003664202     0.5649150014     0.9206114398     0.9279368213     0.8434399118     6.2963140011    \n",
            "4                0.7798970938     0.0003639990     0.7802610993     0.9336785010     0.9466929911     0.8291069460     7.9046497345    \n",
            "5                0.3010375798     0.0003933242     0.3014309108     0.9410749507     0.9506416584     0.8368246968     9.7242608070    \n",
            "6                0.2513729930     0.0003922409     0.2517652214     0.9371301775     0.9496544916     0.8026460860     11.7790563107   \n",
            "7                0.0782936513     0.0002376751     0.0785313249     0.9321992110     0.9466929911     0.8313120176     13.3441107273   \n",
            "8                0.7698150873     0.0003131572     0.7701282501     0.9267751479     0.9299111550     0.8235942668     14.9132583141   \n",
            "9                0.2056377828     0.0004094001     0.2060471773     0.9484714004     0.9605133268     0.8213891951     16.4754576683   \n",
            "\n",
            "========ROUND 3========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 1.0: Avg Val Loss = 0.4569\n",
            "2. Domain 2.0: Avg Val Loss = 0.5015\n",
            "3. Domain 0.0: Avg Val Loss = 0.5346\n",
            "Curriculum learning: Stage 3\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3605284393    \n",
            "1                0.0634217560    \n",
            "2                0.0654577538    \n",
            "3                0.1440476477    \n",
            "4                0.2573224306    \n",
            "5                0.0741822943    \n",
            "6                0.4773944616    \n",
            "7                0.4710789919    \n",
            "8                0.2111467421    \n",
            "9                0.3951064944    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.2154738903     1.2151449919     0.0003288866    \n",
            "1                1.5048786402     1.5045717955     0.0003068244    \n",
            "2                1.0912884474     1.0910210609     0.0002673825    \n",
            "3                1.2595313787     1.2592215538     0.0003097874    \n",
            "4                1.1344161034     1.1341499090     0.0002662014    \n",
            "5                1.2357628345     1.2354185581     0.0003442376    \n",
            "6                1.4556959867     1.4553850889     0.0003109353    \n",
            "7                0.9552646875     0.9549205899     0.0003440972    \n",
            "8                1.5335655212     1.5332173109     0.0003481809    \n",
            "9                0.9974176884     0.9970788956     0.0003388219    \n",
            "Counter({0: 2572, 1: 1482})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.0839565992     0.0003821119     1.0843386650     0.9484714004     0.9526159921     0.8379272326     1.5855956078    \n",
            "1                0.7470155954     0.0002689000     0.7472844720     0.9479783037     0.9516288253     0.8241455347     3.6371543407    \n",
            "2                0.1324513853     0.0003396075     0.1327909976     0.9127218935     0.9230009872     0.8533627343     5.4090824127    \n",
            "3                0.3812478185     0.0002530926     0.3815008998     0.9363905325     0.9417571570     0.8081587652     6.9717562199    \n",
            "4                0.1367876232     0.0002548369     0.1370424628     0.9398422091     0.9585389931     0.8285556781     8.6228606701    \n",
            "5                0.1425295472     0.0003870898     0.1429166347     0.9514299803     0.9555774926     0.8291069460     10.2172918320   \n",
            "6                0.1476313919     0.0002880874     0.1479194760     0.9447731755     0.9516288253     0.8384785006     11.8317205906   \n",
            "7                0.2326620072     0.0003544656     0.2330164760     0.9538954635     0.9575518263     0.8037486218     13.4080648422   \n",
            "8                0.2705707550     0.0002981900     0.2708689570     0.9474852071     0.9486673248     0.8158765160     15.2765507698   \n",
            "9                0.6862739921     0.0003125233     0.6865864992     0.9484714004     0.9664363277     0.8269018743     17.1904692650   \n",
            "\n",
            "========ROUND 4========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 0.5411\n",
            "2. Domain 1.0: Avg Val Loss = 0.5713\n",
            "3. Domain 0.0: Avg Val Loss = 0.6321\n",
            "Curriculum learning: Stage 4\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1050123423    \n",
            "1                0.1815999448    \n",
            "2                0.1175173745    \n",
            "3                0.2620678544    \n",
            "4                0.1438042074    \n",
            "5                0.5555323362    \n",
            "6                0.0607782118    \n",
            "7                0.1748184264    \n",
            "8                0.1951260567    \n",
            "9                0.0881967247    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9112671614     0.9109456539     0.0003214989    \n",
            "1                1.5224053860     1.5220462084     0.0003592042    \n",
            "2                1.1489887238     1.1485620737     0.0004266175    \n",
            "3                0.7304874659     0.7300584316     0.0004290490    \n",
            "4                1.0687482357     1.0683789253     0.0003692739    \n",
            "5                1.0577135086     1.0573945045     0.0003189466    \n",
            "6                1.7664074898     1.7660161257     0.0003913937    \n",
            "7                1.2018976212     1.2015115023     0.0003860815    \n",
            "8                1.3817613125     1.3814377785     0.0003235452    \n",
            "9                1.5200287104     1.5196583271     0.0003703730    \n",
            "Counter({0: 2596, 1: 1458})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1146425083     0.0003077510     0.1149502620     0.9558678501     0.9585389931     0.8042998897     1.6068079472    \n",
            "1                0.1296728998     0.0003295268     0.1300024241     0.9484714004     0.9585389931     0.8120176406     3.1775491238    \n",
            "2                0.2207521051     0.0003836178     0.2211357206     0.9583333333     0.9674234946     0.8054024256     4.7682294846    \n",
            "3                0.1246455014     0.0003501701     0.1249956712     0.9580867850     0.9654491609     0.8202866593     6.3477232456    \n",
            "4                0.3722330928     0.0003488647     0.3725819588     0.9598126233     0.9634748272     0.8009922822     8.6821687222    \n",
            "5                0.2789161205     0.0004365142     0.2793526351     0.9561143984     0.9634748272     0.8015435502     10.3014259338   \n",
            "6                0.6906664371     0.0003892617     0.6910557151     0.9546351085     0.9644619941     0.8125689085     11.9108586311   \n",
            "7                0.1155364811     0.0003710296     0.1159075126     0.9430473373     0.9476801579     0.8175303197     13.5218186378   \n",
            "8                0.0275210217     0.0003347921     0.0278558135     0.9571005917     0.9595261599     0.8153252481     15.1005671024   \n",
            "9                0.1445091069     0.0003862665     0.1448953748     0.9632642998     0.9703849951     0.8169790518     16.6541769505   \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.8277925849    \n",
            "1                0.0998069942    \n",
            "2                0.1528155357    \n",
            "3                0.3082761765    \n",
            "4                0.1125937253    \n",
            "5                0.1226110756    \n",
            "6                0.0590418838    \n",
            "7                0.2299429029    \n",
            "8                0.6728357673    \n",
            "9                0.2632993460    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.3002867699     1.2999545336     0.0003322051    \n",
            "1                0.8124899864     0.8120632172     0.0004267861    \n",
            "2                0.9705281854     0.9702085257     0.0003196399    \n",
            "3                0.7854787111     0.7850697041     0.0004090151    \n",
            "4                1.2081805468     1.2079354525     0.0002450364    \n",
            "5                1.5629703999     1.5626506805     0.0003197003    \n",
            "6                1.2833875418     1.2830486298     0.0003388647    \n",
            "7                1.0095106363     1.0091903210     0.0003202730    \n",
            "8                1.5688235760     1.5685242414     0.0002993266    \n",
            "9                1.5975388288     1.5971757174     0.0003630615    \n",
            "Counter({1: 2416, 0: 1638})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.7328709960     0.0003613773     0.7332323790     0.9479783037     0.9595261599     0.8197353914     2.1586160660    \n",
            "1                0.0121208541     0.0004297764     0.0125506306     0.9484714004     0.9595261599     0.8296582139     3.7730064392    \n",
            "2                0.1933328956     0.0004457434     0.1937786341     0.9635108481     0.9733464956     0.8241455347     5.3688836098    \n",
            "3                0.0715384260     0.0003090618     0.0718474910     0.9603057199     0.9684106614     0.8180815877     6.9937841892    \n",
            "4                0.1642676443     0.0003289798     0.1645966172     0.9536489152     0.9565646594     0.7855567806     8.5644366741    \n",
            "5                0.0119809052     0.0003339686     0.0123148737     0.9531558185     0.9565646594     0.8114663727     10.1633315086   \n",
            "6                0.0286078434     0.0003570060     0.0289648492     0.9593195266     0.9713721619     0.8092613010     11.7531833649   \n",
            "7                0.2402033657     0.0003741226     0.2405774891     0.9612919132     0.9634748272     0.8208379272     13.9036443233   \n",
            "8                0.2374098450     0.0003342016     0.2377440482     0.9561143984     0.9634748272     0.8114663727     15.6178514957   \n",
            "9                0.1035298109     0.0003299331     0.1038597450     0.9501972387     0.9447186575     0.8081587652     17.2080347538   \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4340291321    \n",
            "1                0.0755346790    \n",
            "2                0.8773660064    \n",
            "3                0.3468105197    \n",
            "4                0.1077574268    \n",
            "5                0.3133687675    \n",
            "6                0.2722581923    \n",
            "7                0.0335796215    \n",
            "8                0.1422012895    \n",
            "9                1.1420975924    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.8479460478     0.8476040363     0.0003419953    \n",
            "1                1.2237393856     1.2233991623     0.0003402460    \n",
            "2                1.0384416580     1.0381555557     0.0002860767    \n",
            "3                0.8322708011     0.8319587708     0.0003120355    \n",
            "4                0.9227744341     0.9223470092     0.0004274037    \n",
            "5                1.2518582344     1.2514933348     0.0003648591    \n",
            "6                0.7620170116     0.7616766095     0.0003404035    \n",
            "7                1.1129182577     1.1126255989     0.0002926208    \n",
            "8                1.2240420580     1.2235119343     0.0005300688    \n",
            "9                1.3582389355     1.3578944206     0.0003444984    \n",
            "Counter({0: 2289, 1: 1765})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0575788766     0.0003632784     0.0579421557     0.9558678501     0.9575518263     0.8109151047     1.5961818695    \n",
            "1                0.0941398367     0.0004218089     0.0945616439     0.9543885602     0.9585389931     0.8098125689     3.1523792744    \n",
            "2                0.1752753258     0.0003908109     0.1756661385     0.8079388560     0.8410661402     0.6857772878     4.8151202202    \n",
            "3                0.1371501386     0.0003492222     0.1374993622     0.9580867850     0.9644619941     0.7998897464     6.9866697788    \n",
            "4                0.1346782148     0.0003516055     0.1350298226     0.9534023669     0.9624876604     0.8103638368     8.5736830235    \n",
            "5                0.0018956222     0.0003608139     0.0022564360     0.9625246548     0.9615004936     0.8120176406     10.1360683441   \n",
            "6                0.1282642037     0.0004273065     0.1286915094     0.9482248521     0.9516288253     0.7899669239     11.7179453373   \n",
            "7                0.0792457014     0.0003717502     0.0796174482     0.9558678501     0.9595261599     0.8213891951     13.2744190693   \n",
            "8                0.0492678992     0.0003356370     0.0496035367     0.9568540434     0.9703849951     0.8158765160     14.8588614464   \n",
            "9                0.0505735874     0.0004277399     0.0510013290     0.9627712032     0.9605133268     0.8269018743     16.4210228920   \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3443785310    \n",
            "1                0.4657266736    \n",
            "2                0.1069777757    \n",
            "3                0.0769849792    \n",
            "4                0.2680757344    \n",
            "5                0.8546648026    \n",
            "6                0.0421646088    \n",
            "7                0.5050719976    \n",
            "8                0.4926864505    \n",
            "9                1.4426758289    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.3294308186     1.3291215897     0.0003091694    \n",
            "1                1.1047238111     1.1043528318     0.0003709248    \n",
            "2                1.3479205370     1.3476384878     0.0002820309    \n",
            "3                1.3367613554     1.3364253044     0.0003360147    \n",
            "4                1.1016848087     1.1013048887     0.0003798939    \n",
            "5                1.0878854990     1.0874443054     0.0004411766    \n",
            "6                0.8412919641     0.8409698009     0.0003221483    \n",
            "7                2.2322311401     2.2318401337     0.0003909293    \n",
            "8                0.9276418686     0.9272845984     0.0003572599    \n",
            "9                1.3284854889     1.3281489611     0.0003364708    \n",
            "Counter({1: 2385, 0: 1669})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1978721172     0.0003779196     0.1982500404     0.9511834320     0.9624876604     0.8142227122     1.5690052509    \n",
            "1                0.1175856367     0.0003796312     0.1179652661     0.9450197239     0.9595261599     0.8131201764     3.1707680225    \n",
            "2                0.2040427625     0.0002860613     0.2043288201     0.9598126233     0.9703849951     0.8169790518     4.7353923321    \n",
            "3                0.4780080914     0.0003225283     0.4783306122     0.9442800789     0.9654491609     0.7976846748     6.2962951660    \n",
            "4                0.1336759776     0.0002811752     0.1339571476     0.9571005917     0.9713721619     0.8131201764     7.8563237190    \n",
            "5                0.2663945854     0.0003296731     0.2667242587     0.9336785010     0.9536031589     0.8070562293     9.4714872837    \n",
            "6                0.0892930254     0.0003853132     0.0896783397     0.9566074951     0.9723593287     0.8031973539     11.6615824699   \n",
            "7                0.0753144398     0.0003766305     0.0756910667     0.9494575937     0.9654491609     0.8004410143     13.3092129230   \n",
            "8                0.0523828045     0.0002950537     0.0526778586     0.9588264300     0.9723593287     0.8125689085     14.8760948181   \n",
            "9                0.0343806185     0.0003171656     0.0346977860     0.9571005917     0.9654491609     0.8031973539     16.4698939323   \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1476461887    \n",
            "1                0.7966005802    \n",
            "2                0.1699333042    \n",
            "3                0.0891231224    \n",
            "4                0.3065578341    \n",
            "5                0.0560642332    \n",
            "6                0.2681759894    \n",
            "7                0.0521829501    \n",
            "8                0.0655854270    \n",
            "9                0.1107713506    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.0447895527     1.0443295240     0.0004600183    \n",
            "1                0.8257793784     0.8253449798     0.0004344118    \n",
            "2                1.1510845423     1.1507328749     0.0003516650    \n",
            "3                1.8536707163     1.8532770872     0.0003935721    \n",
            "4                1.4748319387     1.4745434523     0.0002884333    \n",
            "5                1.5323826075     1.5320384502     0.0003441994    \n",
            "6                1.2549731731     1.2546268702     0.0003463228    \n",
            "7                0.9818307161     0.9814756513     0.0003550502    \n",
            "8                1.2520430088     1.2517067194     0.0003362701    \n",
            "9                1.4060677290     1.4056996107     0.0003681747    \n",
            "Counter({1: 2226, 0: 1828})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3191359043     0.0003250310     0.3194609284     0.9573471400     0.9654491609     0.8114663727     1.6025605202    \n",
            "1                0.4689119458     0.0003338548     0.4692457914     0.9506903353     0.9536031589     0.8208379272     3.4064168930    \n",
            "2                0.1444718242     0.0003377117     0.1448095292     0.9571005917     0.9615004936     0.8219404631     5.5041592121    \n",
            "3                0.0060081487     0.0003586365     0.0063667852     0.9534023669     0.9674234946     0.8296582139     7.0672650337    \n",
            "4                1.1474804878     0.0003334921     1.1478140354     0.9546351085     0.9486673248     0.7767364939     8.6487944126    \n",
            "5                0.0803163573     0.0003308702     0.0806472301     0.9541420118     0.9615004936     0.7965821389     10.2134981155   \n",
            "6                0.7274900675     0.0003681967     0.7278582454     0.9600591716     0.9615004936     0.8076074972     11.8004934788   \n",
            "7                0.1368242055     0.0003760346     0.1372002363     0.9566074951     0.9595261599     0.8153252481     13.3724186420   \n",
            "8                0.2807435691     0.0003648331     0.2811084092     0.9504437870     0.9624876604     0.7987872106     14.9416368008   \n",
            "9                0.1724323034     0.0003769879     0.1728092879     0.9580867850     0.9624876604     0.8269018743     17.0677640438   \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1532161832    \n",
            "1                0.0864378437    \n",
            "2                0.3132914305    \n",
            "3                0.2482978255    \n",
            "4                0.0455031432    \n",
            "5                0.0709161311    \n",
            "6                0.8763014078    \n",
            "7                0.2248488814    \n",
            "8                0.6231778264    \n",
            "9                0.9572947025    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.4015129805     1.4011944532     0.0003185064    \n",
            "1                1.5873318911     1.5869555473     0.0003763540    \n",
            "2                1.0305175781     1.0301934481     0.0003241638    \n",
            "3                0.9279584885     0.9276600480     0.0002984107    \n",
            "4                1.5809642076     1.5806186199     0.0003455434    \n",
            "5                1.0889744759     1.0887011290     0.0002733743    \n",
            "6                1.3554093838     1.3550387621     0.0003706006    \n",
            "7                1.5020705462     1.5018540621     0.0002164383    \n",
            "8                0.8700312376     0.8696523309     0.0003788770    \n",
            "9                1.2678438425     1.2675033808     0.0003404628    \n",
            "Counter({0: 2171, 1: 1883})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2164353728     0.0003742472     0.2168096155     0.9578402367     0.9684106614     0.8026460860     1.6719713211    \n",
            "1                0.2048821896     0.0003419150     0.2052241117     0.9578402367     0.9674234946     0.8054024256     3.2775042057    \n",
            "2                0.2366931438     0.0002868957     0.2369800359     0.9469921105     0.9555774926     0.8136714443     4.8463811874    \n",
            "3                0.0478423610     0.0003371862     0.0481795482     0.9652366864     0.9703849951     0.8076074972     6.4333026409    \n",
            "4                0.2571415007     0.0003470989     0.2574886084     0.9499506903     0.9536031589     0.7783902977     8.0395758152    \n",
            "5                0.2413297594     0.0003188937     0.2416486591     0.9605522682     0.9693978282     0.8125689085     10.2213277817   \n",
            "6                0.7136446834     0.0003331399     0.7139778137     0.9521696252     0.9654491609     0.8009922822     11.8071057796   \n",
            "7                0.0111591956     0.0003494552     0.0115086511     0.9575936884     0.9674234946     0.8147739802     13.4009978771   \n",
            "8                0.1048286706     0.0003707913     0.1051994637     0.9531558185     0.9545903258     0.8076074972     14.9960782528   \n",
            "9                0.0613436475     0.0003738897     0.0617175363     0.9649901381     0.9753208292     0.8158765160     16.5843703747   \n",
            "Target acc: 0.8159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 2 --dataset emg --algorithm diversify --latent_domain_num 20 --alpha1 0.5 --alpha 1.0 --lam 0.0 --local_epoch 1 --max_epoch 10 --lr 0.01 --curriculum --output ./data/train_output/act/cross_people-emg-Diversify-2-20-0.5-1-0-1-150-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRZ7NJf4VAAF",
        "outputId": "5427c860-0922-4e05-dfd3-0d7090e26bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:1.0\n",
            "alpha1:0.5\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:20\n",
            "local_epoch:1\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[2]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-2-20-0.5-1-0-1-150-0.01\n",
            "weight_decay:0.0005\n",
            "curriculum:True\n",
            "CL_PHASE_EPOCHS:5\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "========ROUND 0========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 1.7906\n",
            "2. Domain 1.0: Avg Val Loss = 1.7925\n",
            "3. Domain 0.0: Avg Val Loss = 1.8006\n",
            "Curriculum learning: Stage 0\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9106712341    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.4604885578     0.9449004531     1.5155880451    \n",
            "Counter({7: 2805})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5070531964     0.0052900566     0.5123432279     0.2065243464     0.2130518234     0.2135167464     1.0798602104    \n",
            "\n",
            "========ROUND 1========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 4.8418\n",
            "2. Domain 1.0: Avg Val Loss = 5.0910\n",
            "3. Domain 0.0: Avg Val Loss = 5.8764\n",
            "Curriculum learning: Stage 1\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4791880250    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.8739615679     0.6396546364     0.2343069464    \n",
            "Counter({1: 2805})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4325892329     0.0031112216     0.4357004464     0.7140801151     0.7082533589     0.6800239234     1.0541856289    \n",
            "\n",
            "========ROUND 2========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 2.0: Avg Val Loss = 0.7965\n",
            "2. Domain 1.0: Avg Val Loss = 0.8003\n",
            "3. Domain 0.0: Avg Val Loss = 1.1635\n",
            "Curriculum learning: Stage 2\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9540442228    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9808900356     0.9692481756     0.0116418675    \n",
            "Counter({9: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3745799363     0.0015531571     0.3761330843     0.7531782202     0.7610364683     0.6686602871     1.2444572449    \n",
            "\n",
            "========ROUND 3========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 1.0: Avg Val Loss = 0.7643\n",
            "2. Domain 2.0: Avg Val Loss = 0.8877\n",
            "3. Domain 0.0: Avg Val Loss = 1.0939\n",
            "Curriculum learning: Stage 3\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4404823780    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.2283986807     1.2227146626     0.0056840153    \n",
            "Counter({1: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3305294514     0.0017324144     0.3322618604     0.7843607580     0.7610364683     0.7093301435     1.3699629307    \n",
            "\n",
            "========ROUND 4========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 0.6790\n",
            "2. Domain 2.0: Avg Val Loss = 0.8245\n",
            "3. Domain 1.0: Avg Val Loss = 0.8804\n",
            "Curriculum learning: Stage 4\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.3533886671    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.0861965418     1.0841490030     0.0020475632    \n",
            "Counter({4: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1344341636     0.0005985944     0.1350327581     0.8023506836     0.8186180422     0.7793062201     1.2538237572    \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.8036426306    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.8243170977     1.8232624531     0.0010546951    \n",
            "Counter({8: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.1142784357     0.0000688376     1.1143472195     0.7654113696     0.7898272553     0.7254784689     1.2521181107    \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.5902677178    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.3578964472     1.3571166992     0.0007797328    \n",
            "Counter({6: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5804360509     0.0006828506     0.5811188817     0.8253777884     0.8493282150     0.7643540670     1.2331843376    \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.0844895840    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.2800438404     1.2793269157     0.0007169710    \n",
            "Counter({1: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.2398998737     0.0001890120     1.2400889397     0.8268169825     0.8195777351     0.7428229665     1.3598225117    \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1943801939    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6346020699     0.6339851022     0.0006169765    \n",
            "Counter({4: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3966090679     0.0001979460     0.3968070149     0.7805229072     0.7994241843     0.7147129187     1.2517292500    \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3510930538    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.1066085100     1.1060023308     0.0006061726    \n",
            "Counter({4: 4168})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.4251078367     0.0002300223     1.4253379107     0.6828975774     0.6986564299     0.5891148325     1.2537610531    \n",
            "Target acc: 0.7644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 3 --dataset emg --algorithm diversify --latent_domain_num 5 --alpha1 5.0 --alpha 0.1 --lam 0.0 --local_epoch 5 --max_epoch 10 --lr 0.01 --curriculum --output ./data/train_output/act/cross_people-emg-Diversify-3-5-5-0.1-0-5-30-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQnpxLqqVRjr",
        "outputId": "9c2b181c-c87e-4da5-c2cb-2c53972b897b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:0.1\n",
            "alpha1:5.0\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:5\n",
            "local_epoch:5\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[3]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-3-5-5-0.1-0-5-30-0.01\n",
            "weight_decay:0.0005\n",
            "curriculum:True\n",
            "CL_PHASE_EPOCHS:5\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "========ROUND 0========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 1.7837\n",
            "2. Domain 1.0: Avg Val Loss = 1.7919\n",
            "3. Domain 2.0: Avg Val Loss = 1.7949\n",
            "Curriculum learning: Stage 0\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.5916007757    \n",
            "1                0.7259337902    \n",
            "2                0.3939967752    \n",
            "3                0.3839105666    \n",
            "4                0.3890941739    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.3735847473     1.3255586624     0.0480260327    \n",
            "1                1.0706999302     1.0643243790     0.0063754935    \n",
            "2                0.9919031858     0.9903431535     0.0015600536    \n",
            "3                0.9452433586     0.9444631934     0.0007801586    \n",
            "4                0.7930496335     0.7925986648     0.0004509757    \n",
            "Counter({0: 1060, 2: 683, 4: 390, 3: 349, 1: 332})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5081677437     0.0019562435     0.5101239681     0.7914258189     0.7919075145     0.6780862374     1.1677217484    \n",
            "1                0.3900390863     0.0013459431     0.3913850188     0.8263487476     0.8545279383     0.6999409333     2.2927360535    \n",
            "2                0.3453133404     0.0019110866     0.3472244143     0.8391136802     0.8420038536     0.6952155936     3.4013185501    \n",
            "3                0.3388033211     0.0003295644     0.3391328752     0.8422447013     0.8448940270     0.7873597165     4.9482896328    \n",
            "4                0.2655338645     0.0003406867     0.2658745646     0.8441714836     0.8420038536     0.7779090372     6.2871384621    \n",
            "\n",
            "========ROUND 1========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 0.4744\n",
            "2. Domain 1.0: Avg Val Loss = 0.5503\n",
            "3. Domain 2.0: Avg Val Loss = 0.9207\n",
            "Curriculum learning: Stage 1\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2668961883    \n",
            "1                0.4849006832    \n",
            "2                0.2025296092    \n",
            "3                0.3123768866    \n",
            "4                0.3432036340    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9194849730     0.9189287424     0.0005562527    \n",
            "1                0.7165836692     0.7161225677     0.0004610800    \n",
            "2                0.6500031948     0.6495645642     0.0004386393    \n",
            "3                0.5477043986     0.5466413498     0.0010630611    \n",
            "4                0.9905690551     0.9901363850     0.0004326577    \n",
            "Counter({0: 1386, 2: 479, 4: 388, 3: 310, 1: 251})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1873059571     0.0018529927     0.1891589463     0.8506743738     0.8689788054     0.7111636149     1.1329288483    \n",
            "1                0.3090054393     0.0004353969     0.3094408214     0.8506743738     0.8612716763     0.7223862965     2.2737202644    \n",
            "2                0.2617669106     0.0004487253     0.2622156441     0.8701830443     0.8737957611     0.7389249852     3.3955230713    \n",
            "3                0.2557716966     0.0003903980     0.2561621070     0.8622350674     0.8660886320     0.7188422918     4.9496815205    \n",
            "4                0.2650407255     0.0004487476     0.2654894590     0.8771676301     0.8843930636     0.7584170112     6.4408295155    \n",
            "\n",
            "========ROUND 2========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 0.0: Avg Val Loss = 0.2510\n",
            "2. Domain 1.0: Avg Val Loss = 0.3185\n",
            "3. Domain 2.0: Avg Val Loss = 0.9908\n",
            "Curriculum learning: Stage 2\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3586296141    \n",
            "1                0.3662043810    \n",
            "2                0.3182901442    \n",
            "3                0.3147168756    \n",
            "4                0.2365600616    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.4916455150     0.4911842048     0.0004613092    \n",
            "1                0.5607898235     0.5604860187     0.0003037921    \n",
            "2                0.6092824340     0.6089246869     0.0003577582    \n",
            "3                0.7702998519     0.7698577046     0.0004421654    \n",
            "4                0.6646006703     0.6641154289     0.0004852577    \n",
            "Counter({0: 1461, 3: 1002, 1: 672, 2: 538, 4: 478})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3249429166     0.0004434793     0.3253864050     0.9164258189     0.9277456647     0.7731836976     1.3173034191    \n",
            "1                0.1883074492     0.0004313253     0.1887387782     0.9323217726     0.9470134875     0.7702303603     2.7431616783    \n",
            "2                0.2855325639     0.0004213904     0.2859539688     0.9053468208     0.9190751445     0.7802717070     4.5737559795    \n",
            "3                0.2881261706     0.0004133323     0.2885394990     0.9376204239     0.9470134875     0.7720023627     5.9017052650    \n",
            "4                0.1428110301     0.0006417446     0.1434527785     0.9195568401     0.9094412331     0.7554636740     7.1890983582    \n",
            "\n",
            "========ROUND 3========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 1.0: Avg Val Loss = 0.2886\n",
            "2. Domain 2.0: Avg Val Loss = 0.3692\n",
            "3. Domain 0.0: Avg Val Loss = 0.4025\n",
            "Curriculum learning: Stage 3\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3524968624    \n",
            "1                0.3002609015    \n",
            "2                0.2482573688    \n",
            "3                0.2674715519    \n",
            "4                0.2596761584    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.8423018456     0.8418766260     0.0004252332    \n",
            "1                0.9031210542     0.9026660919     0.0004549503    \n",
            "2                0.6391372085     0.6386995912     0.0004376161    \n",
            "3                0.8028590679     0.8022974133     0.0005616802    \n",
            "4                0.5421231985     0.5418678522     0.0002553370    \n",
            "Counter({0: 2474, 1: 828, 3: 294, 4: 291, 2: 264})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1982572973     0.0005563141     0.1988136172     0.9019749518     0.9181117534     0.7531010041     1.7397854328    \n",
            "1                0.1487077177     0.0005664375     0.1492741555     0.9503853565     0.9508670520     0.7849970467     3.1505007744    \n",
            "2                0.1501215398     0.0004357343     0.1505572796     0.9477360308     0.9527938343     0.7826343768     4.4475889206    \n",
            "3                0.1089223176     0.0005769078     0.1094992235     0.9438824663     0.9479768786     0.7637330183     5.7387664318    \n",
            "4                0.0807039291     0.0003956966     0.0810996220     0.9573699422     0.9595375723     0.7643236858     7.0212645531    \n",
            "\n",
            "========ROUND 4========\n",
            "\n",
            "--- Domain Ranking by Difficulty (easiest to hardest) ---\n",
            "1. Domain 1.0: Avg Val Loss = 0.2772\n",
            "2. Domain 0.0: Avg Val Loss = 0.3207\n",
            "3. Domain 2.0: Avg Val Loss = 0.3766\n",
            "Curriculum learning: Stage 4\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3000984490    \n",
            "1                0.1594206542    \n",
            "2                0.1393078864    \n",
            "3                0.1370083392    \n",
            "4                0.1738931388    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9019387960     0.9015067220     0.0004321003    \n",
            "1                0.7900125384     0.7896175981     0.0003949260    \n",
            "2                0.7687732577     0.7681936622     0.0005796221    \n",
            "3                0.9786642194     0.9781004190     0.0005637766    \n",
            "4                1.0223715305     1.0219311714     0.0004403435    \n",
            "Counter({0: 1182, 3: 1043, 2: 884, 4: 604, 1: 438})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0764759406     0.0004265496     0.0769024938     0.9535163776     0.9508670520     0.7666863556     1.3576753139    \n",
            "1                0.0963334441     0.0005005767     0.0968340188     0.9573699422     0.9537572254     0.7601890136     2.6362240314    \n",
            "2                0.1136446223     0.0005462518     0.1141908765     0.9397880539     0.9421965318     0.7584170112     3.9196550846    \n",
            "3                0.0947873294     0.0004278359     0.0952151641     0.9624277457     0.9605009634     0.7655050207     5.2289066315    \n",
            "4                0.0497614667     0.0003604239     0.0501218922     0.9400289017     0.9479768786     0.7418783225     6.5313017368    \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2393157631    \n",
            "1                0.1842325330    \n",
            "2                0.1988411546    \n",
            "3                0.1535415202    \n",
            "4                0.2520077229    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.6865646839     0.6860412955     0.0005234151    \n",
            "1                0.5868512988     0.5863373876     0.0005139335    \n",
            "2                0.6353256702     0.6348545551     0.0004710935    \n",
            "3                1.1357790232     1.1352399588     0.0005390670    \n",
            "4                0.7921389937     0.7917492390     0.0003897445    \n",
            "Counter({0: 1635, 2: 782, 4: 676, 1: 620, 3: 438})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1437274516     0.0004294859     0.1441569328     0.9527938343     0.9325626204     0.7660956881     1.3066728115    \n",
            "1                0.0708966702     0.0004925004     0.0713891685     0.9573699422     0.9633911368     0.7572356763     2.5920436382    \n",
            "2                0.1538399756     0.0005519375     0.1543919146     0.9653179191     0.9653179191     0.7649143532     3.9019384384    \n",
            "3                0.0767687559     0.0004357303     0.0772044882     0.9583333333     0.9518304432     0.7773183698     5.2358827591    \n",
            "4                0.0936502293     0.0003842570     0.0940344855     0.9453275530     0.9441233141     0.7566450089     6.5595479012    \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1002644673    \n",
            "1                0.1787976325    \n",
            "2                0.2832354605    \n",
            "3                0.1371989399    \n",
            "4                0.1993376166    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7819825411     0.7815311551     0.0004513859    \n",
            "1                0.6463217735     0.6457577348     0.0005640521    \n",
            "2                0.8424221873     0.8419408202     0.0004813698    \n",
            "3                0.7240366340     0.7238110900     0.0002255176    \n",
            "4                0.6390755177     0.6387125850     0.0003629166    \n",
            "Counter({0: 1742, 2: 1158, 4: 524, 1: 502, 3: 225})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1010195985     0.0003264902     0.1013460904     0.9641136802     0.9566473988     0.7678676905     1.2912521362    \n",
            "1                0.0705822483     0.0005045204     0.0710867718     0.9703757225     0.9653179191     0.7826343768     2.6289622784    \n",
            "2                0.0472491607     0.0004406624     0.0476898216     0.9600192678     0.9547206166     0.7395156527     4.0316910744    \n",
            "3                0.0700206012     0.0006019451     0.0706225485     0.9600192678     0.9595375723     0.7424689900     5.3235764503    \n",
            "4                0.0501079708     0.0004328743     0.0505408458     0.9670038536     0.9643545279     0.7690490254     6.6657996178    \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.1152928695    \n",
            "1                0.0895546600    \n",
            "2                0.1675440073    \n",
            "3                0.1279352009    \n",
            "4                0.1186873317    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7182938457     0.7178073525     0.0004865002    \n",
            "1                0.6875444055     0.6872269511     0.0003174793    \n",
            "2                1.2131527662     1.2127128839     0.0004399007    \n",
            "3                0.8268792033     0.8264698982     0.0004092982    \n",
            "4                0.5147107840     0.5143100023     0.0004007863    \n",
            "Counter({3: 1351, 0: 1070, 4: 852, 1: 544, 2: 334})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0830875635     0.0004195288     0.0835070908     0.9672447013     0.9653179191     0.7714116952     1.3283183575    \n",
            "1                0.0885112435     0.0003687948     0.0888800398     0.9679672447     0.9633911368     0.7790903721     2.6210212708    \n",
            "2                0.0261188000     0.0004728049     0.0265916046     0.9703757225     0.9691714836     0.7542823390     3.9056313038    \n",
            "3                0.1288305372     0.0005377276     0.1293682605     0.9679672447     0.9585741811     0.7548730065     5.4329957962    \n",
            "4                0.0382116921     0.0004172645     0.0386289582     0.9605009634     0.9624277457     0.7720023627     7.1897072792    \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.0878103822    \n",
            "1                0.0808567554    \n",
            "2                0.1281359643    \n",
            "3                0.1155479252    \n",
            "4                0.0537876599    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.4242379069     0.4238099754     0.0004279274    \n",
            "1                1.0916492939     1.0911955833     0.0004537604    \n",
            "2                1.0900280476     1.0895899534     0.0004381360    \n",
            "3                0.6675801277     0.6671583652     0.0004217387    \n",
            "4                0.5684975386     0.5680301785     0.0004673624    \n",
            "Counter({0: 1336, 3: 1221, 4: 885, 1: 355, 2: 354})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0404325053     0.0004777510     0.0409102552     0.9698940270     0.9749518304     0.7619610159     1.3161461353    \n",
            "1                0.0521858558     0.0004536480     0.0526395030     0.9648362235     0.9614643545     0.7525103367     2.6239731312    \n",
            "2                0.0752630010     0.0003813970     0.0756443962     0.9727842004     0.9633911368     0.7666863556     4.3477761745    \n",
            "3                0.0868493170     0.0004872933     0.0873366073     0.9665221580     0.9691714836     0.7855877141     5.8884069920    \n",
            "4                0.0506990366     0.0004147623     0.0511137992     0.9684489403     0.9701348748     0.7773183698     7.1849200726    \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.0870427862    \n",
            "1                0.2884605229    \n",
            "2                0.0862103254    \n",
            "3                0.3009994328    \n",
            "4                0.1243361533    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.5785486102     0.5781065822     0.0004420441    \n",
            "1                0.7240133882     0.7236168385     0.0003965706    \n",
            "2                0.9241576791     0.9237274528     0.0004302379    \n",
            "3                0.8686271310     0.8682351112     0.0003920043    \n",
            "4                1.2294508219     1.2290101051     0.0004407730    \n",
            "Counter({0: 1594, 1: 864, 3: 756, 4: 606, 2: 331})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0267720446     0.0003681697     0.0271402150     0.9660404624     0.9653179191     0.7749556999     1.3619794846    \n",
            "1                0.0744443834     0.0002847006     0.0747290850     0.9537572254     0.9499036609     0.7495569994     3.1550805569    \n",
            "2                0.0808467120     0.0004304912     0.0812772065     0.9633911368     0.9662813102     0.7613703485     4.5391092300    \n",
            "3                0.0948574394     0.0005240259     0.0953814685     0.9701348748     0.9720616570     0.7572356763     5.8570117950    \n",
            "4                0.0202983096     0.0005062736     0.0208045840     0.9725433526     0.9730250482     0.7690490254     7.1426727772    \n",
            "Target acc: 0.7620\n"
          ]
        }
      ]
    }
  ]
}
